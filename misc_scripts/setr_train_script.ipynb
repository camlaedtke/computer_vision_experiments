{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93925f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('ggplot')\n",
    "plt.rc('xtick',labelsize=16)\n",
    "plt.rc('ytick',labelsize=16)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.activations import gelu\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from utils.plot_utils import plot_iou_trainId, plot_iou_catId, label_to_rgb, display, create_mask\n",
    "from utils.data_utils import get_labels, parse_record, get_dataset_from_tfrecord\n",
    "from utils.train_utils import (weighted_cross_entropy_loss, TrainAccumilator, SETRMTrainAccumilator,\n",
    "                              SETRLTrainAccumilator)\n",
    "from utils.custom_callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import mixed_precision\n",
    "# from data_loaders import CityscapesLoader\n",
    "# from setr import ClassToken, AddPositionEmbs, MultiHeadSelfAttention, TransformerBlock\n",
    "# from tensorflow_addons.layers import GroupNormalization\n",
    "from models.seg.setr import SETR_PUP\n",
    "\n",
    "K.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "def enable_amp():\n",
    "    mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "    \n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(physical_devices,\"\\n\")\n",
    "enable_amp() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ac200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main\" | \n",
    "#    sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list\n",
    "\n",
    "# apt-get install apt-transport-https ca-certificates gnupg\n",
    "\n",
    "# curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | \n",
    "# sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -\n",
    "\n",
    "# sudo apt-get update && sudo apt-get install google-cloud-sdk\n",
    "\n",
    "# gcloud init --console-only\n",
    "\n",
    "# gsutil cp gs://cl_datasets_01/cityscapes/records/trainIds_train.record /mnt/vol_b/records/trainIds_train.record \n",
    "# gsutil cp gs://cl_datasets_01/cityscapes/records/trainIds_val.record /mnt/vol_b/records/trainIds_val.record \n",
    "# gsutil cp gs://cl_datasets_01/cityscapes/records/ /mnt/vol_b/weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb39d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CityscapesLoader():\n",
    "    \n",
    "    def __init__(self, img_height, img_width, n_classes):\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.MEAN = np.array([0.485, 0.456, 0.406])\n",
    "        self.STD = np.array([0.229, 0.224, 0.225])\n",
    "        self.id2label = tf.constant([0,  0,  0,  0,  0,  0,  0,  1,  2,  0,  0,  3,  \n",
    "                                     4,  5,  0,  0,  0,  6,  0,  7,  8,  9,  10, 11, \n",
    "                                    12, 13, 14, 15, 16,  0,  0, 17, 18, 19,  0], tf.int32)\n",
    "        \n",
    "\n",
    "    @tf.function\n",
    "    def random_crop(self, img, seg):\n",
    "        \"\"\"\n",
    "        Inputs: full resolution image and mask\n",
    "        A scale between 0.5 and 1.0 is randomly chosen. \n",
    "        Then, we multiply original height and width by the scale, \n",
    "        and randomly crop to the scaled height and width.\n",
    "        \"\"\"\n",
    "        scales = tf.convert_to_tensor(np.array(\n",
    "        [0.25, 0.3125, 0.375, 0.4375, 0.5, 0.5625, 0.625, 0.6875, 0.75, 0.8125, 0.875, 0.9375, 1.0], \n",
    "            dtype=np.float32))\n",
    "        scale = scales[tf.random.uniform(shape=[], minval=0, maxval=13, dtype=tf.int32)]\n",
    "\n",
    "        shape = tf.cast(tf.shape(img), tf.float32)\n",
    "        h = tf.cast(shape[0] * scale, tf.int32)\n",
    "        w = tf.cast(shape[1] * scale, tf.int32)\n",
    "        combined_tensor = tf.concat([img, seg], axis=2)\n",
    "        combined_tensor = tf.image.random_crop(combined_tensor, size=[h, w, 4])\n",
    "        return combined_tensor[:,:,0:3], combined_tensor[:,:,-1]\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def normalize(self, img):\n",
    "        img = img / 255.0\n",
    "        img = img - self.MEAN\n",
    "        img = img / self.STD\n",
    "        return img\n",
    "\n",
    "    \n",
    "    @tf.function\n",
    "    def load_image_train(self, datapoint):\n",
    "        img = datapoint['image_left']\n",
    "        seg = datapoint['segmentation_label']\n",
    "        \n",
    "        if tf.random.uniform(()) > 0.5:\n",
    "            img = tf.image.flip_left_right(img)\n",
    "            seg = tf.image.flip_left_right(seg)\n",
    "        if tf.random.uniform(()) > 0.5:\n",
    "            img = tf.image.random_brightness(img, 0.1)\n",
    "        if tf.random.uniform(()) > 0.5:\n",
    "            img = tf.image.random_saturation(img, 0.7, 1.3)\n",
    "        if tf.random.uniform(()) > 0.5:\n",
    "            img = tf.image.random_contrast(img, 0.7, 1.3)\n",
    "        if tf.random.uniform(()) > 0.5:\n",
    "            img = tf.image.random_hue(img, 0.05)\n",
    "            \n",
    "        img, seg = self.random_crop(img, seg)\n",
    "        seg = tf.expand_dims(seg, axis=-1)\n",
    "        \n",
    "        img = tf.image.resize(img, (self.img_height, self.img_width), method='bilinear')\n",
    "        seg = tf.image.resize(seg, (self.img_height, self.img_width), method='nearest')\n",
    "        img = self.normalize(tf.cast(img, tf.float32))\n",
    "        \n",
    "        seg = tf.squeeze(seg)\n",
    "        seg = tf.gather(self.id2label, tf.cast(seg, tf.int32))\n",
    "        \n",
    "        return img, seg\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def load_image_test(self, datapoint):\n",
    "        img = datapoint['image_left']\n",
    "        seg = datapoint['segmentation_label']\n",
    "        \n",
    "        img = tf.image.resize(img, (self.img_height, self.img_width), method='bilinear')\n",
    "        seg = tf.image.resize(seg, (self.img_height, self.img_width), method='nearest')\n",
    "        img = self.normalize(tf.cast(img, tf.float32))\n",
    "        \n",
    "        seg = tf.squeeze(seg, axis=-1)\n",
    "        seg = tf.gather(self.id2label, tf.cast(seg, tf.int32))\n",
    "        \n",
    "        return img, seg\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def load_image_eval(self, datapoint):\n",
    "        img = datapoint['image_left']\n",
    "        seg = datapoint['segmentation_label']\n",
    "        seg = tf.expand_dims(seg, axis=-1)\n",
    "        img = tf.image.resize(img, (self.img_height, self.img_width), method='bilinear')\n",
    "        img = self.normalize(tf.cast(img, tf.float32))\n",
    "        seg = tf.squeeze(seg)\n",
    "        seg = tf.gather(self.id2label, tf.cast(seg, tf.int32))\n",
    "        return img, seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50609f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 20\n",
    "img_size = 768\n",
    "patch_size = 16\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "ACCUM_STEPS = 4\n",
    "ADJ_BATCH_SIZE = BATCH_SIZE * ACCUM_STEPS\n",
    "BUFFER_SIZE = 256\n",
    "\n",
    "labels = get_labels()\n",
    "trainid2label = { label.trainId : label for label in labels }\n",
    "catid2label = { label.categoryId : label for label in labels }\n",
    "\n",
    "pipeline = CityscapesLoader(\n",
    "    img_height=img_size, \n",
    "    img_width=img_size, \n",
    "    n_classes=n_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2839b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, info = tfds.load(\n",
    "    name = 'cityscapes/semantic_segmentation', \n",
    "    data_dir = '/workspace/tensorflow_datasets/', \n",
    "    with_info = True,\n",
    "    shuffle_files=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a5da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = info.splits['train'].num_examples\n",
    "VALID_LENGTH = info.splits['validation'].num_examples\n",
    "\n",
    "\n",
    "EPOCHS = 120\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // ADJ_BATCH_SIZE\n",
    "VALIDATION_STEPS = VALID_LENGTH // BATCH_SIZE \n",
    "DECAY_STEPS = (STEPS_PER_EPOCH * EPOCHS) # // ACCUM_STEPS\n",
    "print(\"Decay steps: {}\".format(DECAY_STEPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5a4798",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset['train'].map(pipeline.load_image_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "valid = dataset['validation'].map(pipeline.load_image_test, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "eval_ds = dataset['validation'].map(pipeline.load_image_eval, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset = train.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d363d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in train.take(1): \n",
    "    sample_image, sample_mask = image, mask\n",
    "\n",
    "sample_mask = sample_mask[..., tf.newaxis]\n",
    "sample_mask = label_to_rgb(sample_mask.numpy())\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ec25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in train.take(1): \n",
    "    sample_image, sample_mask = image, mask\n",
    "\n",
    "sample_mask = sample_mask[..., tf.newaxis]\n",
    "sample_mask = label_to_rgb(sample_mask.numpy())\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b86b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in train.take(1): \n",
    "    sample_image, sample_mask = image, mask\n",
    "\n",
    "sample_mask = sample_mask[..., tf.newaxis]\n",
    "sample_mask = label_to_rgb(sample_mask.numpy())\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in train.take(1): \n",
    "    sample_image, sample_mask = image, mask\n",
    "\n",
    "sample_mask = sample_mask[..., tf.newaxis]\n",
    "sample_mask = label_to_rgb(sample_mask.numpy())\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in valid.take(2): \n",
    "    sample_image, sample_mask = image, mask\n",
    "\n",
    "sample_mask = sample_mask[..., tf.newaxis]\n",
    "sample_mask = label_to_rgb(sample_mask.numpy())\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd54ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in valid.take(2): \n",
    "    sample_image, sample_mask = image, mask\n",
    "\n",
    "sample_mask = sample_mask[..., tf.newaxis]\n",
    "sample_mask = label_to_rgb(sample_mask.numpy())\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in valid.take(2): \n",
    "    sample_image, sample_mask = image, mask\n",
    "\n",
    "sample_mask = sample_mask[..., tf.newaxis]\n",
    "sample_mask = label_to_rgb(sample_mask.numpy())\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b8909",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in valid.take(2): \n",
    "    sample_image, sample_mask = image, mask\n",
    "\n",
    "sample_mask = sample_mask[..., tf.newaxis]\n",
    "sample_mask = label_to_rgb(sample_mask.numpy())\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e99c9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_B = {\n",
    "    \"dropout\": 0.1,\n",
    "    \"mlp_dim\": 3072,\n",
    "    \"num_heads\": 12,\n",
    "    \"num_layers\": 12,\n",
    "    \"hidden_size\": 768,\n",
    "    \"aux_layers\": None,\n",
    "    \"name\": \"SETR-B_16\",\n",
    "    \"pretrained\": \"weights/vit_b16_imagenet21k_imagenet2012.h5\"\n",
    "}\n",
    "\n",
    "CONFIG_M = {\n",
    "    \"dropout\": 0.1,\n",
    "    \"mlp_dim\": 4096,\n",
    "    \"num_heads\": 16,\n",
    "    \"num_layers\": 18,\n",
    "    \"hidden_size\": 1024,\n",
    "    \"aux_layers\": [9, 14],\n",
    "    \"name\": \"SETR-M_16\",\n",
    "    \"pretrained\": \"weights/vit_l16_imagenet21k_imagenet2012.h5\"\n",
    "}\n",
    "\n",
    "\n",
    "config = CONFIG_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf07cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca5cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "\n",
    "    # with strategy.scope():\n",
    "\n",
    "    learning_rate_fn = PolynomialDecay(\n",
    "        initial_learning_rate = 5e-3,\n",
    "        decay_steps = DECAY_STEPS,\n",
    "        end_learning_rate = 5e-6,\n",
    "        power = 0.9\n",
    "    )\n",
    "\n",
    "    model = SETR_PUP(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = n_classes,\n",
    "        num_layers = config[\"num_layers\"],\n",
    "        hidden_size = config[\"hidden_size\"],\n",
    "        aux_layers = config[\"aux_layers\"],\n",
    "        num_heads = config[\"num_heads\"],\n",
    "        name = config[\"name\"],\n",
    "        mlp_dim = config[\"mlp_dim\"],\n",
    "        dropout = 0.1,\n",
    "    )\n",
    "    model.load_weights(config[\"pretrained\"], by_name=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = SGD(learning_rate=learning_rate_fn, momentum=0.9),\n",
    "        loss = weighted_cross_entropy_loss,\n",
    "        metrics = ['accuracy', iou_coef]\n",
    "        )\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "def show_predictions():        \n",
    "    pred_mask = model.predict(sample_image[tf.newaxis, ...])\n",
    "    if (model.name == \"SETR-L_16\") or (model.name == \"SETR-M_16\"):\n",
    "        pred_mask = pred_mask[0]\n",
    "    display([sample_image, sample_mask, create_mask(pred_mask)])\n",
    "\n",
    "        \n",
    "def iou_coef(y_true, y_pred):\n",
    "    y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=n_classes)\n",
    "    y_pred = tf.math.argmax(y_pred, axis=-1)\n",
    "    y_pred = tf.one_hot(tf.cast(y_pred, tf.int32), depth=n_classes)\n",
    "    smooth = 1\n",
    "    iou_total = 0\n",
    "    for i in range(1, n_classes):\n",
    "        intersection = tf.math.reduce_sum(y_true[:,:,:,i] * y_pred[:,:,:,i], axis=(1,2))\n",
    "        union = tf.math.reduce_sum(y_true[:,:,:,i] + y_pred[:,:,:,i], axis=(1,2)) \n",
    "        iou = tf.math.reduce_mean(tf.math.divide_no_nan(2.*intersection+smooth, union+smooth), axis=0)\n",
    "        iou_total += iou\n",
    "    return iou_total/(n_classes-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef81200",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_fn = PolynomialDecay(\n",
    "        initial_learning_rate = 1e-2,\n",
    "        decay_steps = DECAY_STEPS,\n",
    "        end_learning_rate = 1e-5,\n",
    "        power = 0.9\n",
    "    )\n",
    "    \n",
    "opt = SGD(learning_rate=learning_rate_fn, momentum=0.9)\n",
    "\n",
    "model = SETR_PUP(\n",
    "    image_size = img_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = n_classes,\n",
    "    num_layers = config[\"num_layers\"],\n",
    "    hidden_size = config[\"hidden_size\"],\n",
    "    aux_layers = config[\"aux_layers\"],\n",
    "    num_heads = config[\"num_heads\"],\n",
    "    name = config[\"name\"],\n",
    "    mlp_dim = config[\"mlp_dim\"],\n",
    "    dropout = 0.1,\n",
    ")\n",
    "model.load_weights(config[\"pretrained\"], by_name=True)\n",
    "\n",
    "# trainer = SETRMTrainAccumilator(\n",
    "#     model = model,\n",
    "#     optimizer = mixed_precision.LossScaleOptimizer(opt),\n",
    "#     loss_fn = weighted_cross_entropy_loss,\n",
    "#     n_classes = n_classes,\n",
    "#     reduce_lr_on_plateau = None,\n",
    "#     accum_steps = ACCUM_STEPS,\n",
    "# )\n",
    "\n",
    "trainer = TrainAccumilator(\n",
    "    model = model,\n",
    "    optimizer = mixed_precision.LossScaleOptimizer(opt),\n",
    "    loss_fn = weighted_cross_entropy_loss,\n",
    "    n_classes = n_classes,\n",
    "    reduce_lr_on_plateau = None,\n",
    "    accum_steps = ACCUM_STEPS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fd89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_model()\n",
    "# model, trainer = get_ga_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09605f8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot_model(model, show_shapes=True, dpi=64, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249eacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"weights/\"+model.name+\".h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47497ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d85e61b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c304b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a8473",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = trainer.fit(\n",
    "    epochs = EPOCHS,\n",
    "    train_dataset = train_dataset,\n",
    "    test_dataset = valid_dataset, \n",
    "    weights_path = MODEL_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e031d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [\n",
    "#     # EarlyStopping(monitor='val_iou_coef', mode='max', patience=40, verbose=2),\n",
    "#     # ReduceLROnPlateau(monitor='val_iou_coef', mode='max', patience=10, factor=0.5, min_lr=1e-5, verbose=2),\n",
    "#     tf.keras.callbacks.ModelCheckpoint(MODEL_PATH, monitor='val_iou_coef', mode='max', \n",
    "#                     verbose=2, save_best_only=True, save_weights_only=True)    \n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = model.fit(\n",
    "#     train_dataset,\n",
    "#     steps_per_epoch=STEPS_PER_EPOCH,\n",
    "#     validation_steps=VALIDATION_STEPS,\n",
    "#     epochs=EPOCHS,\n",
    "#     validation_data=valid_dataset,\n",
    "#     callbacks=callbacks,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65495dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa4cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(results, model):\n",
    "         \n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.subplot(1,3,1)  \n",
    "\n",
    "    plt.plot(results.history['loss'], 'r', label='Training loss')\n",
    "    plt.plot(results.history['val_loss'], 'b', label='Validation loss')\n",
    "    plt.title(\"Loss: \"+model.name, fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.plot(results.history['accuracy'], 'r', label='Training accuracy')\n",
    "    plt.plot(results.history['val_accuracy'], 'b', label='Validation accuracy')\n",
    "    plt.title('Accuracy: '+model.name, fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.plot(results.history['iou_coef'], 'r', label='IoU coefficient')\n",
    "    plt.plot(results.history['val_iou_coef'], 'b', label='Validation IoU coefficient')\n",
    "    plt.title('IoU Coefficient: '+model.name, fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "    \n",
    "    if fine:\n",
    "        plt.savefig(\"plots/\"+model.name+\"_learning_curves.png\")\n",
    "    else:\n",
    "        plt.savefig(\"plots/\"+model.name+\"_learning_curves_coarse.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18190bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(results, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ae213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd84c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
